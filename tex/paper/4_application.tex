\subsection{Data and set-up}
All data used in the empirical exercise was obtained from Thomson Reuters Datastream. We will investigate the forecast performance of various prediction models for 20 Dow Jones constituents for which the Institutional Brokers Estimate System (I/B/E/S) database provide target prices and analyst recommendations. We use monthly observations because the I/B/E/S summary data is aggregated on this frequency. Historical target price data from I/B/E/S is available from April 1999 to October 2014. The initial estimation window has size $h=60$ and hence pseudo out-of-sample evaluation period starts in April 2004. We only consider one-step ahead predictions in this study. For each stock, we compute logarithmic returns (including dividends) and subtract the 3-month T-bill rate %(from the previous period) 
to obtain excess returns. For the choice of the predictor variables, we partly follow \cite{welch2008,pettenuzzo2016} and (i) consider firm specific \textit{fundamentals} such as the log dividend yield, the log earnings price ratio, the log dividend-payout ratio, and the book-to-market ratio, (ii) market and economic measures such as the 3-month T-bill rate, the yield on long-term government bonds, %and the default yield spread (i.e. the yield spread between BAA and AAA rated corporate bonds), (iii) estimates of equity risk such as the long-term return, 
the market excess return and %net equity expansion (the ratio of 12-month net issues by NYSE-listed stocks over the year-end market capitalization) and (iv) macroeconomic indicators such as 
CPI inflation.\\
%
\indent Thomson Reuters I/B/E/S database provides detailed and consensus estimates featuring up 26 forecast measures for more than 70,000 companies in	more than 90 countries worldwide. While, the summary files contain a monthly snapshot of each company followed by sell-side analysts whose brokerage firm provides data to I/B/E/S, the detail files offer forecasts from individual analysts. We are mainly interested in two variables: 
\begin{enumerate}
\item \textbf{Price targets:} The mean and standard deviation of the projected price level forecasted by professional analysts with a 12-month time horizons. At each point in time, we also consider the entire vector of target prices from individual analysts.
\item \textbf{Recommendations summary:} The mean and standard deviation of analysts' recommendation based on a five point standardized scale (strong buy = 1, buy, hold, sell, strong sell = 5) as well as the total number of recommendations, the number of up- and downgrade revisions and the percentage of buy, hold and sell recommendations.
\end{enumerate}
We will use the target price returns and variance as well as the consensus analyst recommendations and their revisions as predictor variables. In particular, target prices will be used to calculate (i) monthly forward target price implied expected return, i.e. simple returns between the spot and the twelve months forward target price at each point $t$ divided by twelve, and (ii) monthly target price implied expected return variances. For this, we used the detail history I/B/E/S files that contain target prices of individual analysts. We first calculate monthly forward target price implied expected returns for every individual analyst and then use the mean and variance of these returns as first and second moment restrictions for the entropic tilting exercise.\\
%
\indent Table \ref{tab:summary} reports the descriptive statistics on the returns, expected target returns and recommendations for the 20 Dow Jones constituents used in this study. While we note that the mean and standard deviations of the logarithmic returns differ substantially across assets, the target price and recommendation characteristics are very similar: All mean forward target price implied expected returns are positive, indicating an upward bias in the target prices compared to the spot prices. The standard deviation of the expected target price returns is generally slightly lower in scale than the standard deviation of the logarithmic stock returns. Moreover, the upward bias can also be seen in the mean recommendations, which is always smaller than three, given the five point scale. A lower score indicates more buy recommendations. The company with the least number target prices of 11 and number of recommendations with 16 is DuPont (DD) and the company with the greatest number of target prices, 28, and recommendations, 39, is Intel (INTC). 

\subsection{Competing models}
We consider a number of different models to distinguish the effects, considering different sets of predictor variables, models with constant and time-varying coefficients as well as mean and variance tilted models. These are
\begin{enumerate}
	\item[1.][AR1] Autoregressive model of order one for the return process of each asset.
	\item[2.][VAR-Full] Bayesian vector autoregressive model of order one with an uninformative prior for all parameters (full specification).
	\item[3.][VAR-Minnesota] Bayesian vector autoregressive model of order one with the Minnesota prior given in (\ref{eqn:priora}) - (\ref{eqn:priorAkl}) to impose the full model for the return and an autoregressive model for all other variables.
	\item[4.][TVPVAR-SV-DMA] Time-varying parameter model with stochastic volatility and using forgetting factors and dynamic model averaging over different prior parameters as described in Section \ref{subsubsec:tvp}.
	\item[5.][TVPVAR-SV-DMS] Time-varying parameter model with stochastic volatility and using forgetting factors and dynamic model selection over different prior parameters as described in Section \ref{subsubsec:tvp}.
	\item[6.][TVPVAR-SV-DMAm] TVP-BVAR with SV using dynamic model averaging with mean tilting using the monthly target price implied expected returns.
	\item[7.][TVPVAR-SV-DMAm/v] TVP-BVAR with SV using dynamic model averaging with mean and variance tilting using the monthly target price implied expected returns.
	\item[8.][TVPVAR-SV-DMSm] TVP-BVAR with SV using dynamic model selection with mean tilting using the monthly target price implied expected returns.
	\item[9.][TVPVAR-SV-DMSm/v] TVP-BVAR with SV using dynamic model selection with mean and variance tilting using the monthly  target price implied expected returns.
	\item[10.][Bayesian lasso] The Bayesian lasso \citep{park2008} is a shrinkage for univariate regressions based on the Laplace prior that can be used to impose an $L_1$-norm penalization on the regression coefficients to shrink them to zero. %i.e.
	%
	%\begin{equation}\label{eqn:lasso}
	%\argmin{A} \sum_{t=1}^T(r_t-X_t'\,A)^2+\lambda\sum_{i=1}^{N}|A_i|,
	%\end{equation}
	%where $\lambda$ is the shrinkage parameter determining the shrinkage intensity. Here, $r_t$ is the asset return and $X_t$ collects the predictor variables. 
	It has been shown to be a strong forecasting device \citep{korobilis2013} and is used here as a benchmark model.
\end{enumerate}

\subsection{Evaluation criteria}
We consider two evaluation criteria in this study. To evaluate the entire predictive accuracy of point forecasts we use the out-of-sample R$^2$. For model $j$, it is given by
\begin{equation}\label{eqn:R2}
\text{R}^2_{OoS,j}=1-\frac{\sum_{i=h+1}^{T}e_{j,i}^2}{\sum_{i=h+1}^{T}e_{0,i}^2},
\end{equation}
where $e_{0,i}=y_i^1-\hat{y}_{0,i}^1=r_i-\hat{r}_{0,i}$ denotes the forecast error of a simple mean or  intercept only model ($r_i=a+\varepsilon_i$) and $e_{j,i}$ the forecast error in the returns of model $j$ at time $i$ and $h$ denotes the end-point of the initial estimation period. Note that we only evaluate the forecast error with respect to the asset return and not with regard to all predictor variables. All errors are obtained by averaging over the (marginal) predictive density function of the asset returns. Values above zero indicate that model $j$ produces lower forecasts error than the intercept only model. Second, to evaluate the predictive distribution, we consider the average log score differential (LSD) given by
\begin{equation}\label{eqn:LSD}
\text{LSD}_{j,t}=\frac{\sum_{i=h+1}^{t}\left(\text{LS}_{j,i}-\text{LS}_{0,i}\right)}{\sum_{i=h+1}^{t}\text{LS}_{0,i}},
\end{equation}
where where $\text{LS}_{j,i}$ is log predictive score of model $j$ at time $i$. Again, values above zero indicate that a given model $j$ shows better forecast performance than the benchmark model, while negative values suggest the opposite.

%\subsection{Results}

\subsection{Individual predictor performance}
Before heading to the main analysis using all predictors, we start by looking at models with only a single predictor in order to investigate which ones have particular forecasting power. For this, we apply a constant parameter model and a time-varying model with stochastic volatility to estimate the system given in (\ref{eqn:ks1987}) - (\ref{eqn:ks1987_2}).\footnote{For the latter, the underlying model parameters are set to $\lambda=0.99$, $\kappa=0.96$ and $\phi=0.5$.} Tables \ref{tab:mRsquard_BVAR} to \ref{tab:mRsquard_TVPVARmv} provide the results for the out-of-sample R$^2$ and Tables \ref{tab:mCLSD_BVAR} to \ref{tab:mCLSD_TVPVARmv} provide the results in terms of the log predictive scores. Bold numbers show positive performance measures, indicating that the one predictor model outperforms the simple intercept only model. We test statistical significance using the \cite{diebold1995} t-tests with a null hypothesis of equal average forecasting ability.\\
%
\indent The results can be summarized as follows: (i) No predictor variable shows significant forecast performance using a constant parameter model (Tables \ref{tab:mRsquard_BVAR} and \ref{tab:mCLSD_BVAR}). (ii) Using the time-varying parameter model with stochastic volatility increases forecast performance for all predictors, most profoundly for the general economic and market indicators (Tables \ref{tab:mRsquard_TVPVAR} and \ref{tab:mCLSD_TVPVAR}). This may be due to the model flexibility which can reflect the nature of asset returns (e.g. heteroskedasticity) much better \citep[see also][]{johannes2014}.  (iii) Tilting the predictive distribution from the TVP-BVAR towards the target price implied expected returns does not increase forecast performance (Tables \ref{tab:mRsquard_TVPVARm} and \ref{tab:mCLSD_TVPVARm}) significantly. (iv) However, tilting the predictive distribution from the TVP-BVAR to posses the mean and variance of the target price implied expected returns does indeed increase forecast performance, but only significantly for a couple of assets and predictors, especially for the models using the target price return and variance as the predictor variables (Tables \ref{tab:mRsquard_TVPVARmv} and \ref{tab:mCLSD_TVPVARmv}).\\
%
\indent To illustrate the effect of the tilting, we plot the baseline and the tilted predictive densities for the IBM stock returns at different times. Figure \ref{fig:ibmdensitym} compares the baselines density against the mean tilted density for the TVPVAR(1) model. It is obvious that the baseline and tilted densities are very similar to each other, only in 2010 and 2012 the mode of tilted distribution seems to be closer to the actual outcome. The similarity in the two distributions thus explains the lack of forecast improvements from mean tilting.  The picture changes when looking at the tilted density of the mean and variance tilted models. In Figure \ref{fig:ibmdensitymv}, we see that the tilted distribution is much more concentrated around the actual outcome in calm market times (2006, 2012) and more flat and has fatter tails than the baseline density in crises times between 2008 and 2010. In the entire sample, the tilted densities are more often stronger concentrated around the true observation than the baseline. This concentration in the density comes from the agreement of the analyst about the future target price and does not imply that the analysts make unbiased forecasts.

\subsection{Complete model performance}
None of the individual predictor models outperformed the intercept only model consistently across all assets. Instead, the individual predictor exercise revealed that especially the time-varying parameters and the stochastic volatility in connecting with the mean and variance tilting can produce significantly better forecasts. Therefore, we now put all predictors in the model and perform dynamic model averaging and selection using the full VAR system for the 13 variables (12 predictors plus the asset return). This leads to the main results of this paper which can be found in Tables \ref{tab:mRsquard_ALL} and \ref{tab:mCLSD_ALL}. While the AR(1) model cannot outperform the mean model, the full BVAR system with uninformative priors clearly gives worst forecasts. This deterioration is likely to reflect over-fitting from the great number of estimable parameters. The Minnesota prior (shrinking many parameters to zero here) instead improves forecast performance, although not significantly. Its performance is similar to the Bayesian lasso. The time-varying models with dynamic model averaging and selection clearly improve the forecast performance further. However, the difference between model averaging and selection is only marginal.  Again, tilting the mean of the predictive distribution towards the target price implied return does not improve the forecast further. This is only achieved when also tilting the variance towards the target price implied return variance, giving significant better forecasts for a wide range of assets.


